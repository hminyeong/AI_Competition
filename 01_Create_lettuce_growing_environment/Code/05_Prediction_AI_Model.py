# -*- coding: utf-8 -*-
"""Prediction_AI_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T3Z7KYFhdTS7Dw0dWe4_AhKZ3rpgI2xK
"""

from google.colab import drive
drive.mount('/content/drive')

"""##### ì‹œê°í™” í•  ë•Œ í•œê¸€ ê¹¨ì§ ë°©ì§€ """

# í•´ë‹¹ ì…€ ì‹¤í–‰í•˜ê³  ëŸ°íƒ€ì„ ë‹¤ì‹œì‹œì‘ í›„ ì•„ë˜ ì…€ ì‹¤í–‰
!sudo apt-get install -y fonts-nanum
!sudo fc-cache -fv
!rm ~/.cache/matplotlib -rf

import matplotlib.pyplot as plt

plt.rc('font', family='NanumBarunGothic')

"""## â—¾Import """

!pip install bayesian-optimization

import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

from scipy.stats import norm
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, train_test_split, KFold
from scipy import stats

from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import  LabelEncoder
from sklearn.metrics import mean_squared_error
import xgboost as xgb
import lightgbm as lgb

from tqdm import tqdm
import re
import glob
import zipfile
import os
import datetime

import warnings
warnings.filterwarnings('ignore')
# %matplotlib inline

"""## â—¾ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° """

path = "/content/drive/MyDrive/01_Prediction/Dataset/"

#--------------- train: ì´ 28ê°œ ìƒì¶” ì¼€ì´ìŠ¤ ---------------#

all_train_input_list = sorted(glob.glob(path + 'train_input/*.csv'))
all_train_target_list = sorted(glob.glob(path + 'train_target/*.csv'))

train_input_df = pd.DataFrame()
train_target_df = pd.DataFrame()

for input_path, target_path in tqdm(zip(all_train_input_list, all_train_target_list)):
  input_df = pd.read_csv(input_path)
  target_df = pd.read_csv(target_path)
  train_input_df = pd.concat([train_input_df, input_df], axis=0, ignore_index=True) # í–‰ë°©í–¥(ìœ„ì•„ë˜)ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ì„ ì´ì–´ë¶™ì„ 
  train_target_df = pd.concat([train_target_df, target_df], axis=0, ignore_index=True) # í–‰ë°©í–¥(ìœ„ì•„ë˜)ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ì„ ì´ì–´ë¶™ì„

#--------------- test: ì´ 5ê°œ ìƒì¶” ì¼€ì´ìŠ¤ ---------------#

all_test_input_list = sorted(glob.glob(path + 'test_input/*.csv'))
all_test_target_list = sorted(glob.glob(path + 'test_target/*.csv'))

test_input_df = pd.DataFrame()
test_target_df = pd.DataFrame()

for input_path, target_path in tqdm(zip(all_test_input_list, all_test_target_list)):
  input_df = pd.read_csv(input_path)
  target_df = pd.read_csv(target_path)
  test_input_df = pd.concat([test_input_df, input_df], axis=0, ignore_index=True) # í–‰ë°©í–¥(ìœ„ì•„ë˜)ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ì„ ì´ì–´ë¶™ì„ 
  test_target_df = pd.concat([test_target_df, target_df], axis=0, ignore_index=True) # í–‰ë°©í–¥(ìœ„ì•„ë˜)ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ì„ ì´ì–´ë¶™ì„

#--------------- submission: Test ìƒì¶” ì¼€ì´ìŠ¤ 5ê°œì— ëŒ€í•œ ì¼ë³„ ì¶”ë¡ í•œ ê²°ê³¼ ---------------#

zip_path = '/content/drive/MyDrive/01_Prediction/Dataset/sample_submission.zip'
extract_zip_folder_path = '/content/drive/MyDrive/01_Prediction/Submission'

with zipfile.ZipFile(zip_path, 'r') as zipObj:
    zipObj.extractall(extract_zip_folder_path)

submission_list = sorted(glob.glob(extract_zip_folder_path + '/*.csv'))

submission_df = pd.DataFrame()

for submission_path in tqdm(submission_list):
  df = pd.read_csv(submission_path)
  submission_df = pd.concat([submission_df, df], axis=0, ignore_index=True) # í–‰ë°©í–¥(ìœ„ì•„ë˜)ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ì„ ì´ì–´ë¶™ì„

"""## â—¾EDA

##### [ ë°ì´í„° ë‘˜ëŸ¬ë³´ê¸° ]
"""

#--------------- train: ì´ 28ê°œ ìƒì¶” ì¼€ì´ìŠ¤ ---------------#

print(train_input_df.shape, train_target_df.shape)

# train_input_df # 18816 rows(28*672) Ã— 16 columns
# train_target_df # 784 rows(28*28) x 2 columns

#--------------- test: ì´ 5ê°œ ìƒì¶” ì¼€ì´ìŠ¤ ---------------#

print(test_input_df.shape, test_target_df.shape)

# test_input_df # 3360 rows(5*672) Ã— 16 columns
# test_target_df # 140 rows(5*28) x 2 columns

#--------------- submission: Test ìƒì¶” ì¼€ì´ìŠ¤ 5ê°œì— ëŒ€í•œ ì¼ë³„ ì¶”ë¡ í•œ ê²°ê³¼ ---------------#

print(submission_df.shape)

# submission_df # 140 rows(5*28) Ã— 2 columns

train_input_df.info()

train_target_df.info()

test_input_df.info()

test_target_df.info()

submission_df.info()

"""##### [ í”¼ì²˜ ìš”ì•½í‘œ ]  
ê²°ê³¼  
=> ìŒìˆ˜ê°’ì´ ì¡´ì¬í•¨. ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ìŒìˆ˜ê°’ ì²˜ë¦¬í•  ê²ƒ.
"""

def resumetable(df):
    print(f'train dataset í”¼ì²˜ ìš”ì•½í‘œ: {df.shape}')
    summary = pd.DataFrame(df.dtypes, columns=['ë°ì´í„° íƒ€ì…'])
    summary = summary.reset_index()
    summary = summary.rename(columns={'index': 'í”¼ì²˜'})
    summary['ê²°ì¸¡ê°’ ê°œìˆ˜'] = df.isnull().sum().values
    summary['ê³ ìœ³ê°’ ê°œìˆ˜'] = df.nunique().values
    summary['ì²« ë²ˆì§¸ ê°’'] = df.loc[0].values
    summary['ë‘ ë²ˆì§¸ ê°’'] = df.loc[1].values
    summary['ìµœì†Œê°’'] = df.min().values
    summary['ìµœëŒ€ê°’'] = df.max().values
    
    return summary

resumetable(train_input_df)

"""## â—¾ Feature EngineeringğŸ”¹

##### [ í”¼ì²˜ëª… í•œê¸€í™” ]
"""

train_input_df = train_input_df.rename(columns={'DAT': 'ìƒìœ¡ì¼', 'obs_time': 'ì¸¡ì •ì‹œê°„'})
test_input_df = test_input_df.rename(columns={'DAT': 'ìƒìœ¡ì¼', 'obs_time': 'ì¸¡ì •ì‹œê°„'})
train_target_df = train_target_df.rename(columns={'DAT': 'ìƒìœ¡ì¼', 'predicted_weight_g': 'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'})
test_target_df = test_target_df.rename(columns={'DAT': 'ìƒìœ¡ì¼', 'predicted_weight_g': 'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'})

"""##### [ ì¸¡ì •ì‹œê°„ ìˆ˜ì • ]  
'14:59:59' -> '15:00:00'ìœ¼ë¡œ ë°”ê¾¼ í›„ ì§„í–‰í•´ì•¼ í•¨
(ì´ˆë‹¨ìœ„ê°€ 59ë©´ 1ì´ˆì”© ë”í•¨)
"""

train_input_df.loc[train_input_df['ì¸¡ì •ì‹œê°„'].astype(str).str.len()!=5].index

#--------------- train ì´ 28ê°œ ìƒì¶” ì¼€ì´ìŠ¤ ---------------#

train_input_df['ì¸¡ì •ì‹œê°„'] = train_input_df['ì¸¡ì •ì‹œê°„'].str.replace(".", "") #"00:00:00." -> "00:00:00"
plus_one_second = datetime.timedelta(seconds=1)

for i in tqdm(range(len(train_input_df['ì¸¡ì •ì‹œê°„']))):
  if len(train_input_df['ì¸¡ì •ì‹œê°„'][i]) < 6: #"00:00" í˜•ì‹
    train_input_df['ì¸¡ì •ì‹œê°„'][i] = train_input_df['ì¸¡ì •ì‹œê°„'][i] + ":00"
  train_input_df['ì¸¡ì •ì‹œê°„'][i] = pd.to_datetime(train_input_df['ì¸¡ì •ì‹œê°„'][i], format='%H:%M:%S')
  # ì´ˆë‹¨ìœ„ê°€ 59ë©´ 1ì´ˆì”© ë”í•¨ 
  str_time = str(train_input_df['ì¸¡ì •ì‹œê°„'][i])
  if str_time[-2:] == '59':
    train_input_df['ì¸¡ì •ì‹œê°„'][i] = train_input_df['ì¸¡ì •ì‹œê°„'][i] + plus_one_second

train_input_df['ì¸¡ì •ì‹œê°„'] = pd.to_datetime(train_input_df['ì¸¡ì •ì‹œê°„'])
# train_input_df['ì¸¡ì •ì‹œê°„'] = train_input_df['ì¸¡ì •ì‹œê°„'].dt.hour #ì‹œ

train_input_df = train_input_df.reset_index() 
train_input_df = train_input_df.drop(['index'], axis=1) 

train_input_df.head(5) # 18816 rows Ã— 16 columns

#--------------- test ì´ 5ê°œ ìƒì¶” ì¼€ì´ìŠ¤ ---------------#

test_input_df['ì¸¡ì •ì‹œê°„'] = test_input_df['ì¸¡ì •ì‹œê°„'].str.replace(".", "") #"00:00:00." -> "00:00:00"
plus_one_second = datetime.timedelta(seconds=1)

for i in tqdm(range(len(test_input_df['ì¸¡ì •ì‹œê°„']))):
  if len(test_input_df['ì¸¡ì •ì‹œê°„'][i]) < 6: #"00:00" í˜•ì‹
    test_input_df['ì¸¡ì •ì‹œê°„'][i] = test_input_df['ì¸¡ì •ì‹œê°„'][i] + ":00"
  test_input_df['ì¸¡ì •ì‹œê°„'][i] = pd.to_datetime(test_input_df['ì¸¡ì •ì‹œê°„'][i], format='%H:%M:%S')
  # ì´ˆë‹¨ìœ„ê°€ 59ë©´ 1ì´ˆì”© ë”í•¨ 
  str_time = str(test_input_df['ì¸¡ì •ì‹œê°„'][i])
  if str_time[-2:] == '59':
    test_input_df['ì¸¡ì •ì‹œê°„'][i] = test_input_df['ì¸¡ì •ì‹œê°„'][i] + plus_one_second

test_input_df['ì¸¡ì •ì‹œê°„'] = pd.to_datetime(test_input_df['ì¸¡ì •ì‹œê°„'])
# test_input_df['ì¸¡ì •ì‹œê°„'] = test_input_df['ì¸¡ì •ì‹œê°„'].dt.hour #ì‹œ

test_input_df = test_input_df.reset_index() 
test_input_df = test_input_df.drop(['index'], axis=1) 

test_input_df.head(5) # 3360 rows Ã— 16 columns

"""## â—¾ Feature Engineering - í”¼ì²˜ ì¶”ê°€ğŸ”¹

##### [ 'ìƒì¶”' í”¼ì²˜ ì¶”ê°€ ]  
ìƒì¶” caseë³„ë¡œ ì‹œê°í™”í•˜ê¸° ìœ„í•¨.
"""

#--------------- train ì´ 28ê°œ ìƒì¶” ì¼€ì´ìŠ¤ ---------------#

train_input_df['ìƒì¶”'] = "NaN"
train_input_df = train_input_df[['ìƒì¶”', 'ìƒìœ¡ì¼', 'ì¸¡ì •ì‹œê°„','ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜', 'ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜', 'co2ê´€ì¸¡ì¹˜', 'ecê´€ì¸¡ì¹˜', 'ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰',
                                'ì¼ê°„ëˆ„ì ë¶„ë¬´ëŸ‰', 'ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ë°±ìƒ‰ê´‘ëŸ‰', 'ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì ìƒ‰ê´‘ëŸ‰', 'ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰',
                                'ì¼ê°„ëˆ„ì ì²­ìƒ‰ê´‘ëŸ‰', 'ì‹œê°„ë‹¹ì´ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰']]

for idx in range(28):
  train_input_df['ìƒì¶”'][672*idx:672*(idx+1)] = 'case' + str(idx+1)

train_input_df # 18816 rows Ã— 17 columns

#--------------- train_target ì´ 28ê°œ ìƒì¶” ì¼€ì´ìŠ¤ ---------------#

train_target_df['ìƒì¶”'] = "NaN"
train_target_df = train_target_df[['ìƒì¶”', 'ìƒìœ¡ì¼', 'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰']]

for idx in range(28):
  train_target_df['ìƒì¶”'][28*idx:28*(idx+1)] = 'case' + str(idx+1)

train_target_df # 784 rows Ã— 3 columns

#--------------- test ì´ 5ê°œ ìƒì¶” ì¼€ì´ìŠ¤ ---------------#

test_input_df['ìƒì¶”'] = "NaN"
test_input_df = test_input_df[['ìƒì¶”', 'ìƒìœ¡ì¼', 'ì¸¡ì •ì‹œê°„', 'ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜', 'ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜', 'co2ê´€ì¸¡ì¹˜', 'ecê´€ì¸¡ì¹˜', 'ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰',
                              'ì¼ê°„ëˆ„ì ë¶„ë¬´ëŸ‰', 'ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ë°±ìƒ‰ê´‘ëŸ‰', 'ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì ìƒ‰ê´‘ëŸ‰', 'ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰',
                              'ì¼ê°„ëˆ„ì ì²­ìƒ‰ê´‘ëŸ‰', 'ì‹œê°„ë‹¹ì´ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰']]

for idx in range(28):
  test_input_df['ìƒì¶”'][672*idx:672*(idx+1)] = 'case' + str(idx+1+28) # test_input_df ë’¤ì— ë¶™ì¼ê±°ê¸° ë•Œë¬¸ì— case28~case32 ì´ì–´ì•¼ í•¨. 

test_input_df # 3360 rows Ã— 17 columns

#--------------- test_target ì´ 5ê°œ ìƒì¶” ì¼€ì´ìŠ¤ ---------------#

test_target_df['ìƒì¶”'] = "NaN"
test_target_df = test_target_df[['ìƒì¶”', 'ìƒìœ¡ì¼', 'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰']]

for idx in range(28):
  test_target_df['ìƒì¶”'][28*idx:28*(idx+1)] = 'case' + str(idx+1+28)

test_target_df # 140 rows Ã— 3 columns

"""## â—¾ ì‹œê°í™”

##### [ train_input_df 28ê°œ ìƒì¶” caseì— ëŒ€í•œ í”¼ì²˜ë³„ ë¶„í¬ ]
"""

# ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

# ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

# co2ê´€ì¸¡ì¹˜

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['co2ê´€ì¸¡ì¹˜'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

# ecê´€ì¸¡ì¹˜

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['ecê´€ì¸¡ì¹˜'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

# ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

# ì¼ê°„ëˆ„ì ë¶„ë¬´ëŸ‰

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['ì¼ê°„ëˆ„ì ë¶„ë¬´ëŸ‰'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

# ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

# ì¼ê°„ëˆ„ì ë°±ìƒ‰ê´‘ëŸ‰

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['ì¼ê°„ëˆ„ì ë°±ìƒ‰ê´‘ëŸ‰'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

# ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

# ì¼ê°„ëˆ„ì ì ìƒ‰ê´‘ëŸ‰

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['ì¼ê°„ëˆ„ì ì ìƒ‰ê´‘ëŸ‰'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

# ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

# ì¼ê°„ëˆ„ì ì²­ìƒ‰ê´‘ëŸ‰

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['ì¼ê°„ëˆ„ì ì²­ìƒ‰ê´‘ëŸ‰'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

# ì‹œê°„ë‹¹ì´ê´‘ëŸ‰

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['ì‹œê°„ë‹¹ì´ê´‘ëŸ‰'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

# ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰

fig, ax = plt.subplots(ncols=7, nrows=4, figsize=(20,10))

case_idx = 0
for row_idx in range(4):
  for col_idx in range(0, 7):
    sns.distplot(train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(case_idx+1)]['ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰'], ax=ax[row_idx, col_idx])
    case_idx = case_idx + 1

"""##### [ train_input_df í”¼ì²˜ë“¤ì„ ìˆ˜ì¹˜ ê°¯ìˆ˜, ë°ì´í„° ê°¯ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ë§‰ëŒ€ê·¸ë˜í”„ ê·¸ë¦¬ê¸° ]"""

# train_x, train_y = LoadData('train').read_train_raw()                           # trainë°ì´í„°ë¥¼ ì „ì²˜ë¦¬ ì—†ì´ ì½ì–´ì˜¨ë‹¤.

data_count = (train_input_df.isnull()==False).sum()
null_count = (train_input_df.isnull()==True).sum()
float_count = (train_input_df.fillna(0).astype(bool)).sum()
data = [null_count, float_count, data_count]
index = ['null_count','float_count','data_count']
df = pd.DataFrame(data=data, index=index).T

df = df.sort_values('float_count')                                              # ìˆ˜ì¹˜ ê°¯ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬
plt.figure(figsize=(8,10))
plt.title('0ë³´ë‹¤ í° ìˆ˜ì¹˜ ê°¯ìˆ˜')
sns.barplot(y=df.index, x=df['float_count'])                                    # ë§‰ëŒ€ê·¸ë˜í”„ë¥¼ ê·¸ë¦°ë‹¤.
plt.show()

df = df.sort_values('data_count')                                               # ë°ì´í„° ê°¯ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬
plt.figure(figsize=(8,10))
plt.title('ë°ì´í„° ê°¯ìˆ˜')
sns.barplot(y=df.index, x=df['data_count'])                                     # ë§‰ëŒ€ê·¸ë˜í”„ë¥¼ ê·¸ë¦°ë‹¤.
plt.show()

"""##### [ train_input_dfì˜ caseë³„ í”¼ì²˜ë“¤ì˜ í•˜ë£¨ 24ì‹œê°„ ë³€í™”ëŸ‰ ì‚´í´ë³´ê¸° ]"""

FEATURES = train_input_df.columns

from plotly.subplots import make_subplots
import plotly.graph_objs as go

for i in range(1, 29):
  train_case = train_input_df.loc[train_input_df['ìƒì¶”']=='case'+str(i)]

  SAMPLE_NUM = 24
  COLS = FEATURES[3:]
  fig = make_subplots(rows=len(COLS), cols=1, subplot_titles=COLS)
  for row, col in enumerate(COLS, 1):
      fig.add_trace(go.Scatter(x=np.arange(SAMPLE_NUM), y=train_case[col].iloc[:SAMPLE_NUM], showlegend=False,
                          mode='lines+markers', name=col, marker=dict(color="orange")), row=row, col=1)

  fig.update_layout(height=5000, width=1000, title_text='case'+str(i))
  fig.show()

"""## â—¾ Data Pre-processing

##### [ train_input_df ì˜ëª»ëœ ê°’ ë³€ê²½(ìŒìˆ˜ -> ë‹¤ë¥¸ ê°’ìœ¼ë¡œ ë³€ê²½) ]
"""

resumetable(train_input_df)

# ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰ ìŒìˆ˜ -> 0
# 23.7950618671ë¡œ ì˜¬ë¼ê° 

# train_input_df[train_input_df['ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰']<0].index  # [8665, 8713]
train_input_df['ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰'].loc[[8665, 8713]] = 0
train_input_df.loc[[8665, 8713]]

# ì¼ê°„ëˆ„ì ë¶„ë¬´ëŸ‰ ë‹¤ì‹œ êµ¬í•˜ê¸° 
for idx in tqdm(range(644)): # 644
    time_series = train_input_df[24*idx:24*(idx+1)]['ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰']
    train_input_df[24*idx:24*(idx+1)]['ì¼ê°„ëˆ„ì ë¶„ë¬´ëŸ‰'] = time_series.cumsum()

# ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰
# ë‹¤ë¥¸ case ì‚´í´ë³´ê³  ê·¸ ì‹œê°„ëŒ€ì— ëŠ˜ì–´ë‚œ ì–‘ë§Œí¼ ë¹„ìŠ·í•˜ê²Œ ìˆ«ì ì •í•¨

# train_input_df[train_input_df['ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰']<0] # 3375
train_input_df['ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰'].loc[[3375]] = 17744.6635 # í˜¹ì€ 18255.1900	
train_input_df.loc[[3375]]

# ì¼ê°„ëˆ„ì ë°±ìƒ‰ê´‘ëŸ‰ ë‹¤ì‹œ êµ¬í•˜ê¸° 
for idx in tqdm(range(644)): # 644
    time_series = train_input_df[24*idx:24*(idx+1)]['ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰']
    train_input_df[24*idx:24*(idx+1)]['ì¼ê°„ëˆ„ì ë°±ìƒ‰ê´‘ëŸ‰'] = time_series.cumsum()

# ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰ 
# ë‹¤ë¥¸ case ì‚´í´ë³´ê³  ê·¸ ì‹œê°„ëŒ€ì— ëŠ˜ì–´ë‚œ ì–‘ë§Œí¼ ë¹„ìŠ·í•˜ê²Œ ìˆ«ì ì •í•¨

# train_input_df[train_input_df['ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰']<0] # 3375
train_input_df['ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰'].loc[[3375]] = 1859.7644	 # 1659.7644ì—ì„œ ì„ì˜ë¡œ 200 ë”í•¨	(1659.7644ëŠ” 3374í–‰ì˜ ê°’ )
train_input_df.loc[[3375]]

# ì¼ê°„ëˆ„ì ì ìƒ‰ê´‘ëŸ‰ ë‹¤ì‹œ êµ¬í•˜ê¸° 
for idx in tqdm(range(644)): # 644
    time_series = train_input_df[24*idx:24*(idx+1)]['ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰']
    train_input_df[24*idx:24*(idx+1)]['ì¼ê°„ëˆ„ì ì ìƒ‰ê´‘ëŸ‰'] = time_series.cumsum()

# ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰ 
# ë‹¤ë¥¸ case ì‚´í´ë³´ê³  ê·¸ ì‹œê°„ëŒ€ì— ëŠ˜ì–´ë‚œ ì–‘ë§Œí¼ ë¹„ìŠ·í•˜ê²Œ ìˆ«ì ì •í•¨

# train_input_df[train_input_df['ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰']<0] # 3375
train_input_df['ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰'].loc[[3375]] = 3519.6695	 # 3419.6695ì—ì„œ ì„ì˜ë¡œ 100 ë”í•¨	(3419.6695ëŠ” 3374í–‰ì˜ ê°’ )
train_input_df.loc[[3375]]

# ì¼ê°„ëˆ„ì ì²­ìƒ‰ê´‘ëŸ‰ ë‹¤ì‹œ êµ¬í•˜ê¸° 
for idx in tqdm(range(644)): # 644
    time_series = train_input_df[24*idx:24*(idx+1)]['ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰']
    train_input_df[24*idx:24*(idx+1)]['ì¼ê°„ëˆ„ì ì²­ìƒ‰ê´‘ëŸ‰'] = time_series.cumsum()

# ì‹œê°„ë‹¹ì´ê´‘ëŸ‰ 
# ë‹¤ë¥¸ case ì‚´í´ë³´ê³  ê·¸ ì‹œê°„ëŒ€ì— ëŠ˜ì–´ë‚œ ì–‘ë§Œí¼ ë¹„ìŠ·í•˜ê²Œ ìˆ«ì ì •í•¨

# train_input_df[train_input_df['ì‹œê°„ë‹¹ì´ê´‘ëŸ‰']<0] # 3375
train_input_df['ì‹œê°„ë‹¹ì´ê´‘ëŸ‰'].loc[[3375]] = 23634.6239	 # 23334.6239	ì—ì„œ ì„ì˜ë¡œ 300 ë”í•¨	(23334.6239	ëŠ” 3374í–‰ì˜ ê°’ )
train_input_df.loc[[3375]]

# ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰ ë‹¤ì‹œ êµ¬í•˜ê¸° 
for idx in tqdm(range(644)): # 644
    time_series = train_input_df[24*idx:24*(idx+1)]['ì‹œê°„ë‹¹ì´ê´‘ëŸ‰']
    train_input_df[24*idx:24*(idx+1)]['ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰'] = time_series.cumsum()

resumetable(train_input_df)

"""## â—¾ Feature Engineering - íŒŒìƒ í”¼ì²˜ ì¶”ê°€ (ì˜¨ë„, ìŠµë„ ê´€ë ¨)ğŸ”¹

*   ìƒìœ¡ ì ì˜¨: 15~20ë„ 
*   ìµœì €í•œê³„ì˜¨ë„: 8, ìµœê³ í•œê³„ì˜¨ë„: 25  
*   10ë„ ì´í•˜ì´ê±°ë‚˜ 15ë„ ì´ìƒì—ì„œëŠ” ìì˜ ë¶„í™”ê°€ ê±°ì˜ ì´ë£¨ì–´ì§€ì§€ ì•Šê±°ë‚˜ ìì´ ì¦ê°€í•˜ì§€ ì•ŠìŒ  
*   30ë„ ì´ìƒì˜ ê³ ì˜¨ê³¼ 5ë„ ì´í•˜ì˜ ì €ì˜¨ì—ì„œëŠ” ë°œì•„ê°€ ê±°ì˜ ë˜ì§€ ì•ŠìŒ  
*   ìš°ë¦¬ë‚˜ë¼ëŠ” ì—¬ë¦„ì—ëŠ” ì§€ë‚˜ì¹˜ê²Œ ê³ ì˜¨ìœ¼ë¡œ íŠ¹íˆ, ì‹œì„¤ ë‚´ì—ì„œëŠ” í™˜ê¸°ì‹œì„¤ì„ ëª¨ë‘ ê°œë°©í•˜ê³ ë„ ì‹¤ë‚´ì˜¨ë„ê°€35~40oC ì •ë„ë¡œ ì˜¬ë¼ê°€ëŠ”ë°, ì´ëŸ¬í•œ ìƒíƒœì—ì„œëŠ” ë§ì€ ì‘ë¬¼ì˜ ìƒìœ¡ì ì˜¨ì„ ë²—ì–´ë‚œ ì˜¨ë„ë¡œì„œ ê³ ì˜¨ì¥í•´ë¥¼ ë°›ëŠ”ë‹¤.  
*   ë¶ˆì¾Œ ì§€ìˆ˜ = 0.81 Ã— ì˜¨ë„ + 0.01 Ã— ìŠµë„ x (0.99 Ã— ì˜¨ë„ -14.3) +46.3  
---
=> ì´ 3ê°€ì§€ íŒŒìƒ í”¼ì²˜ ìƒì„±   
   **'ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„'**, **'ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„'**, **'ë¶ˆì¾Œì§€ìˆ˜'**

##### [ 'ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„' ]
"""

def good_internal_temperature(df):
  df['ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 0

  # ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜ 15-20â„ƒ
  index_ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ = df.loc[(df['ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜']>=15) & (df['ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜']<=20)].index

  # case ë³„ë¡œ ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„ êµ¬í•˜ê¸° 
  df.loc[index_ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡, 'ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 1
  df['ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„'] = df.groupby(['ìƒì¶”'])['ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„'].apply(lambda x: x.cumsum())
  return df

train_input_df = good_internal_temperature(train_input_df)
test_input_df = good_internal_temperature(test_input_df)

"""##### [ 'ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„' ]"""

def bad_internal_temperature(df):
  df['ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 0

  # ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜ 30â„ƒì´ìƒ, 5â„ƒì´í•˜
  index_ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ = df.loc[(df['ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜']>=30) | (df['ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜']<=5)].index

  # case ë³„ë¡œ ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„ êµ¬í•˜ê¸° 
  df.loc[index_ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡, 'ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 1
  df['ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„'] = df.groupby(['ìƒì¶”'])['ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„'].apply(lambda x: x.cumsum())
  return df

train_input_df = bad_internal_temperature(train_input_df)
test_input_df = bad_internal_temperature(test_input_df)

"""##### [ 'ë¶ˆì¾Œì§€ìˆ˜' ]

"""

#--------------- train ì´ 28ê°œ ìƒì¶” ì¼€ì´ìŠ¤ ---------------#

train_input_df['ë¶ˆì¾Œì§€ìˆ˜'] = (0.81*train_input_df['ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜']) + ((0.01*train_input_df['ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜'])*(0.99*train_input_df['ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜']-14.3)) + 46.3

#--------------- test ì´ 5ê°œ ìƒì¶” ì¼€ì´ìŠ¤ ---------------#

test_input_df['ë¶ˆì¾Œì§€ìˆ˜'] = (0.81*test_input_df['ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜']) + ((0.01*test_input_df['ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜'])*(0.99*test_input_df['ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜']-14.3)) + 46.3

"""##### columns ìˆœì„œ ì •ë¦¬ """

train_input_df = train_input_df[['ìƒì¶”', 'ìƒìœ¡ì¼', 'ì¸¡ì •ì‹œê°„', 
                                 'ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜', 'ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„',
                                 'ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜', 
                                 'ë¶ˆì¾Œì§€ìˆ˜',
                                 'co2ê´€ì¸¡ì¹˜', 'ecê´€ì¸¡ì¹˜', 
                                 'ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰', 'ì¼ê°„ëˆ„ì ë¶„ë¬´ëŸ‰', 
                                 'ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ë°±ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì²­ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì´ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰']]

test_input_df = test_input_df[['ìƒì¶”', 'ìƒìœ¡ì¼', 'ì¸¡ì •ì‹œê°„', 
                                 'ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜', 'ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„',
                                 'ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜', 
                                 'ë¶ˆì¾Œì§€ìˆ˜',
                                 'co2ê´€ì¸¡ì¹˜', 'ecê´€ì¸¡ì¹˜', 
                                 'ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰', 'ì¼ê°„ëˆ„ì ë¶„ë¬´ëŸ‰', 
                                 'ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ë°±ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì²­ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì´ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰']]

"""## â—¾ Feature Engineering - íŒŒìƒ í”¼ì²˜ ì¶”ê°€ (co2 ê´€ë ¨)ğŸ”¹

*   ì˜¨ì‹¤ ë‚´ì˜ CO2 ë†ë„ë¥¼ 1,000~1,500ppm ìˆ˜ì¤€ìœ¼ë¡œ ê³µê¸‰í•˜ë©´ ì—½ì±„ë¥˜(ìƒì¶”, ì‹œê¸ˆì¹˜ ë“±)ì™€ ê³¼ì±„ë¥˜(ê³ ì¶”, í† ë§ˆí† , ì˜¤ì´ ë“±)ì˜ ìˆ˜ëŸ‰ì´ ê°ê° 2.4ë°°, 1.4ë°° í–¥ìƒë˜ì—ˆë‹¤.
---
=> ì´ 2ê°€ì§€ íŒŒìƒ í”¼ì²˜ ìƒì„±  
**'ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„'** , **'ë¶€ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„'**

##### [ 'ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„' ]
"""

def good_co2_time(df):
  df['ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 0

  # CO2 ë†ë„ 1,000~1,500ppm (ì–´ì°¨í”¼ ìµœëŒ€ê°’ 1,200)
  index_ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„ = df.loc[(df['ecê´€ì¸¡ì¹˜']>=1000) & (df['ecê´€ì¸¡ì¹˜']<=1500)].index

  # case ë³„ë¡œ ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„ êµ¬í•˜ê¸° 
  df.loc[index_ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„, 'ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 1
  df['ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„'] = df.groupby(['ìƒì¶”'])['ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„'].apply(lambda x: x.cumsum())
  return df

train_input_df = good_co2_time(train_input_df)
test_input_df = good_co2_time(test_input_df)

"""##### [ 'ë¶€ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„' ]"""

def bad_co2_time(df):
  df['ë¶€ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 0

  # CO2 ë†ë„ 1,000ppm ë¯¸ë§Œ (ì–´ì°¨í”¼ ìµœëŒ€ê°’ 1,200)
  index_ë¶€ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„ = df.loc[(df['ecê´€ì¸¡ì¹˜']<1000)].index

  # case ë³„ë¡œ ë¶€ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„ êµ¬í•˜ê¸° 
  df.loc[index_ë¶€ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„, 'ë¶€ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 1
  df['ë¶€ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„'] = df.groupby(['ìƒì¶”'])['ë¶€ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„'].apply(lambda x: x.cumsum())
  return df

train_input_df = bad_co2_time(train_input_df)
test_input_df = bad_co2_time(test_input_df)

"""##### columns ìˆœì„œ ì •ë¦¬ """

train_input_df = train_input_df[['ìƒì¶”', 'ìƒìœ¡ì¼', 'ì¸¡ì •ì‹œê°„', 
                                 'ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜', 'ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„',
                                 'ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜', 
                                 'co2ê´€ì¸¡ì¹˜', 'ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ë¶€ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„', 
                                 'ecê´€ì¸¡ì¹˜',
                                 'ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰', 'ì¼ê°„ëˆ„ì ë¶„ë¬´ëŸ‰', 
                                 'ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ë°±ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì²­ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì´ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰']]

test_input_df = test_input_df[['ìƒì¶”', 'ìƒìœ¡ì¼', 'ì¸¡ì •ì‹œê°„', 
                                 'ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜', 'ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„',
                                 'ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜', 
                                 'co2ê´€ì¸¡ì¹˜', 'ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ë¶€ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„', 
                                 'ecê´€ì¸¡ì¹˜',
                                 'ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰', 'ì¼ê°„ëˆ„ì ë¶„ë¬´ëŸ‰', 
                                 'ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ë°±ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì²­ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì´ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰']]

"""## â—¾ Feature Engineering - íŒŒìƒ í”¼ì²˜ ì¶”ê°€ (ec ê´€ë ¨)ğŸ”¹

*  ECëŠ” 'ì „ê¸°ì „ë„ë„'ë¼ê³  í•œë‹¤. í† ì–‘ì˜ ë¬´ê¸°ì—¼ë¥˜ ë° NaCl í•¨ìœ ëŸ‰ì„ ì•Œì•„ë³¼ ìˆ˜ ìˆë‹¤.   
ë¹„ë£Œë¥¼ íˆ¬ì…í•´ ì–‘ë¶„ì´ ë§ì•„ì§€ë©´ ì „ê¸°ì „ë„ë„ ì¸¡ì •ê°’ì€ ì»¤ì§€ê²Œ ë˜ê³ , ì‹ë¬¼ì— ì˜í•´ ì–‘ë¶„ì´ ì†Œë¹„ë˜ê³  ë‚˜ë©´ ì¸¡ì •ê°’ì€ ì‘ì•„ì§€ê²Œ ëœë‹¤.  
ECê°€ ë„ˆë¬´ ë†’ìœ¼ë©´ ì‘ë¬¼ì— í”¼í•´ê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤.  
*  ë³´í†µ ì‘ë¬¼ ì¬ë°°ì— ì í•©í•œ í† ì–‘ì˜ ì ì •ECëŠ” 2.0ds/m ì´í•˜ì´ë©°, ì´ìƒì—ì„œëŠ” ì‘ë¬¼ì˜ ìƒìœ¡ì´ ì €í•˜ë˜ê³  ì‹¬í•  ê²½ìš° ì¥í•´ë¥¼ ì¼ìœ¼í‚¨ë‹¤.  
(Ex. ìƒì¶”ëŠ” 1.5 ì´í•˜ë¡œ ê´€ë¦¬í•˜ëŠ”ê²ƒì´ ë°”ëŒì§ í•˜ë‹¤.)  
*  ìƒì¶” ìƒìœ¡ì— ì•Œë§ì€ ì „ê¸°ì „ë„ë„(EC)ëŠ” 1.2~1.6 dS/m ì¸ë° ê³„ì ˆë³„ë¡œ ì—¬ë¦„ì² ì—ëŠ” 1.2 dS/m ê¹Œì§€ ë‚®ì¶°ì£¼ëŠ” ê²ƒì´ ì¢‹ê³  ê²¨ìš¸ì² ì—ëŠ” 1.6 dS/më¡œ ìœ ì§€í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.  
---
=> ì´ 4ê°€ì§€ íŒŒìƒ í”¼ì²˜ ìƒì„± 

*   ecê´€ì¸¡ì¹˜ 1.2â„ƒì´ìƒ, 1.6â„ƒì´í•˜ -> ***'ì ì • ECê´€ì¸¡ ëˆ„ì ì‹œê°„'*** í”¼ì²˜
*   ì—¬ë¦„ì² (8ì›” ê¸°ì¤€. ì˜¨ë„ 19.7-26.7â„ƒ, ìŠµë„ 78-79%) & ecê´€ì¸¡ì¹˜ 1.2ì´ìƒ~1.3ë¯¸ë§Œ  -> ***'ì—¬ë¦„ì²  ì ì • ECê´€ì¸¡ ëˆ„ì ì‹œê°„'*** í”¼ì²˜   
*   ê²¨ìš¸ì² (1ì›” ê¸°ì¤€. ì˜¨ë„ â€“6.9â„ƒ-3.6â„ƒ, ìŠµë„  61-63%) & ecê´€ì¸¡ì¹˜ 1.6ì´ìƒ~1.7ë¯¸ë§Œ -> ***'ê²¨ìš¸ì²  ì ì • ECê´€ì¸¡ ëˆ„ì ì‹œê°„'*** í”¼ì²˜   
*   ecê´€ì¸¡ì¹˜ 1.2 ë¯¸ë§Œ, 1.6 ì´ˆê³¼ -> **'ë¶€ì ì  ECê´€ì¸¡ ëˆ„ì ì‹œê°„'** í”¼ì²˜

##### [ 'ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„' ]
"""

def good_ec_time(df):
  df['ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 0

  # ecê´€ì¸¡ì¹˜ 1.2â„ƒì´ìƒ, 1.6â„ƒì´í•˜
  index_ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„ = df.loc[(df['ecê´€ì¸¡ì¹˜']>=1.2) & (df['ecê´€ì¸¡ì¹˜']<=1.6)].index

  # case ë³„ë¡œ ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„ êµ¬í•˜ê¸° 
  df.loc[index_ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„, 'ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 1
  df['ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'] = df.groupby(['ìƒì¶”'])['ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'].apply(lambda x: x.cumsum())
  return df

train_input_df = good_ec_time(train_input_df)
test_input_df = good_ec_time(test_input_df)

"""##### [ 'ì—¬ë¦„ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„']"""

def summer_good_ec_time(df):
  df['ì—¬ë¦„ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 0

  # ì—¬ë¦„ì² (8ì›” ê¸°ì¤€. ì˜¨ë„ 19.7-26.7â„ƒ, ìŠµë„ 78-79%) & ecê´€ì¸¡ì¹˜ 1.2ì´ìƒ~1.3ë¯¸ë§Œ
  index_ì—¬ë¦„ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„ = df.loc[
        ((df['ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜']>=19.7) & (df['ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜']<=26.7)) 
      & ((df['ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜']>=78) & (df['ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜']<=79))
      & ((df['ecê´€ì¸¡ì¹˜']>=1.2) & (df['ecê´€ì¸¡ì¹˜']<=1.6))].index

  # case ë³„ë¡œ ì—¬ë¦„ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„ êµ¬í•˜ê¸° 
  df.loc[index_ì—¬ë¦„ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„, 'ì—¬ë¦„ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 1
  df['ì—¬ë¦„ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'] = df.groupby(['ìƒì¶”'])['ì—¬ë¦„ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'].apply(lambda x: x.cumsum())
  return df

train_input_df = summer_good_ec_time(train_input_df)
test_input_df = summer_good_ec_time(test_input_df)

"""##### [ 'ê²¨ìš¸ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„' ]"""

def winter_good_ed_time(df):
  df['ê²¨ìš¸ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 0

  # ê²¨ìš¸ì² (1ì›” ê¸°ì¤€. ì˜¨ë„ â€“6.9â„ƒ-3.6â„ƒ, ìŠµë„ 61-63%) & ecê´€ì¸¡ì¹˜ 1.6ì´ìƒ~1.7ë¯¸ë§Œ
  index_ê²¨ìš¸ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„ = df.loc[
        ((df['ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜']>=-6.9) & (df['ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜']<=-3.6)) 
      & ((df['ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜']>=61) & (df['ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜']<=63))
      & ((df['ecê´€ì¸¡ì¹˜']>=1.6) & (df['ecê´€ì¸¡ì¹˜']<1.7))].index

  # case ë³„ë¡œ ê²¨ìš¸ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„ êµ¬í•˜ê¸° 
  df.loc[index_ê²¨ìš¸ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„, 'ê²¨ìš¸ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 1
  df['ê²¨ìš¸ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'] = df.groupby(['ìƒì¶”'])['ê²¨ìš¸ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'].apply(lambda x: x.cumsum())
  return df

train_input_df = winter_good_ed_time(train_input_df)
test_input_df = winter_good_ed_time(test_input_df)

"""##### [ 'ë¶€ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„' ]"""

def bad_ec_time(df):
  df['ë¶€ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 0

  # ecê´€ì¸¡ì¹˜ 1.2â„ƒë¯¸ë§Œ, 1.6â„ƒì´ˆê³¼
  index_ë¶€ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„ = df.loc[(df['ecê´€ì¸¡ì¹˜']>1.2) | (df['ecê´€ì¸¡ì¹˜']<1.6)].index

  # case ë³„ë¡œ ë¶€ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„ êµ¬í•˜ê¸° 
  df.loc[index_ë¶€ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„, 'ë¶€ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'] = 1
  df['ë¶€ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'] = df.groupby(['ìƒì¶”'])['ë¶€ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„'].apply(lambda x: x.cumsum())
  return df

train_input_df = bad_ec_time(train_input_df)
test_input_df = bad_ec_time(test_input_df)

"""##### columns ìˆœì„œ ì •ë¦¬ """

train_input_df = train_input_df[['ìƒì¶”', 'ìƒìœ¡ì¼', 'ì¸¡ì •ì‹œê°„', 
                                 'ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜', 'ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„',
                                 'ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜', 
                                 'co2ê´€ì¸¡ì¹˜', 'ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ë¶€ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„',
                                 'ecê´€ì¸¡ì¹˜', 'ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ë¶€ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ì—¬ë¦„ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ê²¨ìš¸ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„',
                                 'ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰', 'ì¼ê°„ëˆ„ì ë¶„ë¬´ëŸ‰', 
                                 'ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ë°±ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì²­ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì´ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰']]

test_input_df = test_input_df[['ìƒì¶”', 'ìƒìœ¡ì¼', 'ì¸¡ì •ì‹œê°„', 
                                 'ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜', 'ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ë¶€ì ì •_ë‚´ë¶€ì˜¨ë„ê´€ì¸¡_ëˆ„ì ì‹œê°„',
                                 'ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜', 
                                 'co2ê´€ì¸¡ì¹˜', 'ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ë¶€ì ì •_co2ê´€ì¸¡_ëˆ„ì ì‹œê°„',
                                 'ecê´€ì¸¡ì¹˜', 'ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ë¶€ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ì—¬ë¦„ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„', 'ê²¨ìš¸ì² _ì ì •_ECê´€ì¸¡_ëˆ„ì ì‹œê°„',
                                 'ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰', 'ì¼ê°„ëˆ„ì ë¶„ë¬´ëŸ‰', 
                                 'ì‹œê°„ë‹¹ë°±ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ë°±ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì²­ìƒ‰ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì²­ìƒ‰ê´‘ëŸ‰', 
                                 'ì‹œê°„ë‹¹ì´ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰']]

"""##  â—¾ Feature Engineering - íŒŒìƒ í”¼ì²˜ ì¶”ê°€ (ê´‘ ê´€ë ¨)ğŸ”¹

*   ë°œì•„ í›„ ìƒì¶”ì˜ ìƒìœ¡ ê³¼ì •ì—ì„œ ê´‘ë³´ìƒì ì€ 1,500Luxì´ê³  ê´‘í¬í™”ì ì€ 2ë§Œ5,000Luxì´ë‹¤.
*   ì¼ì¥ì€ í•˜ë£¨ ë‚®ì˜ ê¸¸ì´ë¥¼ ë§í•˜ëŠ”ë° ìì—°ì¼ì¥ì€ ì§€ì—­ê³¼ ê³„ì ˆì— ë”°ë¼ ë‹¬ë¼ ì ë„ì§€ë°©ì—ì„œëŠ” ì—°ì¤‘ 12ì‹œê°„ì´ë©° ìœ„ë„ê°€ ë†’ì•„ì§ˆìˆ˜ë¡ ì—¬ë¦„ì˜ ì¼ì¥ì€ ê¸¸ì–´ì§€ê³  ê²¨ìš¸ì€ ì§§ì•„ì§€ê²Œ ëœë‹¤. 
*   ì‹ë¬¼ì˜ ìƒìœ¡ì€ ì¼ì¥ì— ë”°ë¼ ì—¬ëŸ¬ê°€ì§€ ë°˜ì‘ì„ ë³´ì´ëŠ”ë° ì´ë¥¼ ì¼ì¥íš¨ê³¼ë¼ê³  í•œë‹¤. 
---
=> ì´ 2ê°€ì§€ íŒŒìƒ í”¼ì²˜ ìƒì„±  
**'ê´‘ì£¼ê¸°_ëª…ê¸°_ëˆ„ì ì‹œê°„'**, **'ê´‘ì£¼ê¸°_ì•”ê¸°_ëˆ„ì ì‹œê°„'**

##### ['ê´‘ì£¼ê¸°_ëª…ê¸°_ëˆ„ì ì‹œê°„']
"""

def light_time(df):
  df['ê´‘ì£¼ê¸°_ëª…ê¸°_ëˆ„ì ì‹œê°„'] = 0

  index_ê´‘ì£¼ê¸°_ëª…ê¸°_ëˆ„ì ì‹œê°„ = df.loc[df['ì‹œê°„ë‹¹ì´ê´‘ëŸ‰']>0].index

  # case ë³„ë¡œ index_ê´‘ì£¼ê¸°_ëª…ê¸°_ëˆ„ì ì‹œê°„ êµ¬í•˜ê¸° 
  df.loc[index_ê´‘ì£¼ê¸°_ëª…ê¸°_ëˆ„ì ì‹œê°„, 'ê´‘ì£¼ê¸°_ëª…ê¸°_ëˆ„ì ì‹œê°„'] = 1
  df['ê´‘ì£¼ê¸°_ëª…ê¸°_ëˆ„ì ì‹œê°„'] = df.groupby(['ìƒì¶”', 'ìƒìœ¡ì¼'])['ê´‘ì£¼ê¸°_ëª…ê¸°_ëˆ„ì ì‹œê°„'].apply(lambda x: x.cumsum())
  return df

train_input_df = light_time(train_input_df)
test_input_df = light_time(test_input_df)

"""##### ['ê´‘ì£¼ê¸°_ì•”ê¸°_ëˆ„ì ì‹œê°„']"""

def light_time(df):
  df['ê´‘ì£¼ê¸°_ì•”ê¸°_ëˆ„ì ì‹œê°„'] = 0

  index_ê´‘ì£¼ê¸°_ì•”ê¸°_ëˆ„ì ì‹œê°„ = df.loc[df['ì‹œê°„ë‹¹ì´ê´‘ëŸ‰']==0].index

  # case ë³„ë¡œ index_ê´‘ì£¼ê¸°_ì•”ê¸°_ëˆ„ì ì‹œê°„ êµ¬í•˜ê¸° 
  df.loc[index_ê´‘ì£¼ê¸°_ì•”ê¸°_ëˆ„ì ì‹œê°„, 'ê´‘ì£¼ê¸°_ì•”ê¸°_ëˆ„ì ì‹œê°„'] = 1
  df['ê´‘ì£¼ê¸°_ì•”ê¸°_ëˆ„ì ì‹œê°„'] = df.groupby(['ìƒì¶”', 'ìƒìœ¡ì¼'])['ê´‘ì£¼ê¸°_ì•”ê¸°_ëˆ„ì ì‹œê°„'].apply(lambda x: x.cumsum())
  return df

train_input_df = light_time(train_input_df)
test_input_df = light_time(test_input_df)

"""## â—¾ Feature Engineering - íŒŒìƒ í”¼ì²˜ ì¶”ê°€ (ê¸°ì¡´ í”¼ì²˜ë“¤ ì¡°í•©)ğŸ”¹"""

def combine_feature(df) :
    # 2* ê¸°ì¡´ featureë“¤ ì¡°í•©
    df["ì˜¨ë„_ìŠµë„"] = df["ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜"] * df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"]
    df["ì˜¨ë„_co2"] = df["ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜"] * df["co2ê´€ì¸¡ì¹˜"]
    df["ì˜¨ë„_ec"] = df["ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜"] * df["ecê´€ì¸¡ì¹˜"]
    df["ì˜¨ë„_ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"] = df["ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"]
    df["ì˜¨ë„_ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"] = df["ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"]
    df["ì˜¨ë„_ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"] = df["ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜"] * df["ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"]

    df["ìŠµë„_co2"] = df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["co2ê´€ì¸¡ì¹˜"]
    df["ìŠµë„_ec"] = df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["ecê´€ì¸¡ì¹˜"]
    df["ìŠµë„_ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"] = df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"]
    df["ìŠµë„_ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"] = df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"]
    df["ìŠµë„_ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"] = df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"]

    df["co2_ec"] = df["co2ê´€ì¸¡ì¹˜"] * df["ecê´€ì¸¡ì¹˜"]
    df["co2_ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"] = df["co2ê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"]
    df["co2_ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"] = df["co2ê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"]
    df["co2_ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"] = df["co2ê´€ì¸¡ì¹˜"] * df["ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"]

    df["ec_ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"] = df["ecê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"]
    df["ec_ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"] = df["ecê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"]
    df["ec_ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"] = df["ecê´€ì¸¡ì¹˜"] * df["ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"]

    df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰_ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"] = df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"] * df["ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"]
    df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰_ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"] = df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"] * df["ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"]

    df["ì‹œê°„ë‹¹ì´ê´‘ëŸ‰_ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"] = df["ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"] * df["ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"]


    # 3* ê¸°ì¡´ featureë“¤ ì¡°í•©
    df["ì˜¨ë„_ìŠµë„_co2"] = df["ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜"] * df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["co2ê´€ì¸¡ì¹˜"]
    df["ì˜¨ë„_ìŠµë„_ec"] = df["ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜"] * df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["ecê´€ì¸¡ì¹˜"]
    df["ì˜¨ë„_ìŠµë„_ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"] = df["ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜"] * df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"]
    df["ì˜¨ë„_ìŠµë„_ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"] = df["ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜"] * df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"]
    df["ì˜¨ë„_ìŠµë„_ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"] = df["ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜"] * df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"]

    df["ìŠµë„_co2_ec"] = df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["co2ê´€ì¸¡ì¹˜"] * df["ecê´€ì¸¡ì¹˜"]
    df["ìŠµë„_co2_ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"] = df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["co2ê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"]
    df["ìŠµë„_co2_ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"] = df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["co2ê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"]
    df["ìŠµë„_co2_ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"] = df["ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜"] * df["co2ê´€ì¸¡ì¹˜"] * df["ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"]

    df["co2_ec_ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"] = df["co2ê´€ì¸¡ì¹˜"] * df["ecê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"]
    df["co2_ec_ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"] = df["co2ê´€ì¸¡ì¹˜"] * df["ecê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"]
    df["co2_ec_ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"] = df["co2ê´€ì¸¡ì¹˜"] * df["ecê´€ì¸¡ì¹˜"] * df["ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"]

    df["ec_ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰_ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"] = df["ecê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"] * df["ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"]
    df["ec_ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰_ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"] = df["ecê´€ì¸¡ì¹˜"] * df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"] * df["ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"]

    df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰_ì‹œê°„ë‹¹ì´ê´‘ëŸ‰_ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"] = df["ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰"] * df["ì‹œê°„ë‹¹ì´ê´‘ëŸ‰"] * df["ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰"]
    return df

train_input_df = combine_feature(train_input_df)
test_input_df = combine_feature(test_input_df)

"""## â—¾Dataset split

##### [ train_input_df -> train_df, valid_df, test_df ] 23:5:5
"""

train_input_df

test_input_df

train_df = train_input_df[:15456] # case1~case23     24*28*23
valid_df = train_input_df[15456:] # case24~case28  
test_df = test_input_df           # case29~case33

train_target = train_target_df[:644] # case1~case23  28*23
valid_target = train_target_df[644:] # case24~case28
test_target = test_target_df         # case29~case33

print(train_df.shape, valid_df.shape, test_df.shape)
print(train_target.shape, valid_target.shape, test_target.shape)

# train_input_df.loc[train_input_df['ìƒì¶”']=='case24'] # 15456 í–‰ë¶€í„°

# train_target_df.loc[train_target_df['ìƒì¶”']=='case24'] # 644 í–‰ë¶€í„°

"""##### [ to_csv ]"""

path = "/content/drive/MyDrive/01_Prediction/My_Dataset/"

train_df.to_csv(path+"train_df.csv", mode='w', index=False)
valid_df.to_csv(path+"valid_df.csv", mode='w', index=False)
test_df.to_csv(path+"test_df.csv", mode='w', index=False)

train_target.to_csv(path+"train_target.csv", mode='w', index=False)
valid_target.to_csv(path+"valid_target.csv", mode='w', index=False)
test_target.to_csv(path+"test_target.csv", mode='w', index=False)

"""## â—¾Target ê°’ ë¡œê·¸ ë³€í™˜ """

#descriptive statistics summary
train_target['ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'].describe()

plt.figure()
sns.displot(train_target['ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'], bins=30)
plt.xlabel('case')
plt.title('Distribution of ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰')
plt.show()

# 'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰' ë¡œê·¸ ë³€í™˜ í›„ ì›ë˜ 'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰' ë”°ë¡œ ì €ì¥
train_target['log_weight'] = np.log1p(train_target['ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'])
train_real_weight = train_target['ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'] # ì›ë˜ ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰
print(train_target.head(1))

valid_target['log_weight'] = np.log1p(valid_target['ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'])
valid_real_weight = valid_target['ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'] # ì›ë˜ ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰
print(valid_target.head(1))

f, (ax1, ax2) = plt.subplots(1,2,figsize=(12,6))

ax1.hist(train_real_weight, bins=30)
ax1.set_title('weight Distribution')
ax1.set_xlabel('weight')

ax2.hist(train_target['log_weight'], bins=30)
ax2.set_title('Log weight Distribution')
ax2.set_xlabel('Log weight')

plt.show()

f, (ax1, ax2) = plt.subplots(1,2,figsize=(12,6))

ax1.hist(valid_real_weight, bins=30)
ax1.set_title('weight Distribution')
ax1.set_xlabel('weight')

ax2.hist(valid_target['log_weight'], bins=30)
ax2.set_title('Log weight Distribution')
ax2.set_xlabel('Log weight')

plt.show()

"""## â—¾Modeling   
*   [XGBRegressor_1218_80(light_delete).zip]  
    **ì œì¶œ1) public score: 5.5072071055**  
---

1. í‰ê°€ì§€í‘œ  
ëŒ€íšŒì˜ í‰ê°€ì§€í‘œëŠ” RMSEì´ë‚˜, íƒ€ê¹ƒê°’ì— logë¥¼ ì·¨í–ˆê¸° ë•Œë¬¸ì— RMSEë¥¼ êµ¬í•˜ëŠ”ê²Œ RMSLEë¥¼ êµ¬í•˜ëŠ” ê²ƒê³¼ ë™ì¹˜.  
í•™ìŠµì—ëŠ” ì´ë¥¼ ì‚¬ìš©í•˜ê³ , test íŒŒì¼ì—ì„œëŠ” ì—­ë³€í™˜ì„ í•´ì„œ RMSEê°€ ì œëŒ€ë¡œ í‰ê°€ë  ìˆ˜ ìˆê²Œ ì§„í–‰.

2. êµì°¨ê²€ì¦

3. ëª¨ë¸ ë¹„êµ  
ì—¬ëŸ¬ê°œì˜ ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ RMSLEë¥¼ ë¹„êµí•˜ê³ , ê°€ì¥ ë‚®ì€ RMSLEê°€ ë‚˜ì˜¨ ëª¨ë¸ì„ ì„ ì •í•´ íŠœë‹.  
'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'ì„ ì˜ˆì¸¡í•˜ëŠ” íšŒê·€ ëª¨í˜•ì„ ì‚¬ìš©.  

  -  ëª¨ë¸ ëª©ë¡  
  GradientBoosting Regressor  
  XGBoost Regressor  
  LightGBM Regressor
"""

def time_series_df(df, df_target, FEATURES):
  df = df[FEATURES]
  data_list = []
  ts_df = pd.DataFrame()
  for idx in range(len(df_target)): # 644
      time_series = df[24*idx:24*(idx+1)].values  # case1-1, case1-2, case1-3, ...
      time_series = time_series.tolist()
      time_series = sum(time_series, []) # 2 dim -> 1 dim
      time_series_transepose = pd.DataFrame(time_series).transpose()
      ts_df = ts_df.append(time_series_transepose)
      # train_data_list.append(torch.Tensor(time_series))
  return ts_df

FEATURES = ['ìƒìœ¡ì¼', 'ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜', 'ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜', 'co2ê´€ì¸¡ì¹˜', 'ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰', 'ì‹œê°„ë‹¹ì´ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰', 'ec_ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰_ì‹œê°„ë‹¹ì´ê´‘ëŸ‰']

ts_train_df = time_series_df(train_df, train_target, FEATURES)
ts_valid_df = time_series_df(valid_df, valid_target, FEATURES)
ts_test_df = time_series_df(test_df, test_target, FEATURES)

ts_train_target = train_target['log_weight']
ts_valid_target = train_target['log_weight']
ts_test_target = test_target

ts_train_valid_df = ts_train_df.append(ts_valid_df).reset_index(drop=True)
ts_train_valid_target_df = train_target.append(valid_target).reset_index(drop=True)
ts_train_valid_target_df = ts_train_valid_target_df['log_weight']

print(ts_train_valid_df.shape, ts_train_valid_target_df.shape) # log_weight
print(ts_test_df.shape, ts_test_target.shape)   # ìƒì¶”	ìƒìœ¡ì¼	ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰

from scipy import sparse

X_train = sparse.csr_matrix(ts_train_valid_df)
Y_train = ts_train_valid_target_df.values 

X_test = ts_test_df
Y_test = test_target

X_train.shape, Y_train.shape

#Validation function
n_folds = 5

def RMSE(y, y_pred):
    rmse = mean_squared_error(y, y_pred) ** 0.5
    return rmse

def rmsle_cv(model):
    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train)
    rmse= np.sqrt(-cross_val_score(model, X_train, Y_train, scoring="neg_mean_squared_error", cv = kf))
    return(rmse)

"""##### GradientBoostingRegressor"""

model_gb = GradientBoostingRegressor(n_estimators=3000, 
                                     learning_rate=0.05,
                                     max_depth=4,
                                     max_features='sqrt',
                                     min_samples_leaf=15,
                                     min_samples_split=10,
                                     loss='huber',
                                     random_state=2020
                                     )

score = rmsle_cv(model_gb)
gb_score = score.mean()
print("GradientBoostingRegressor score: {:.4f} ({:.4f})".format(score.mean(), score.std()))

model_gb.fit(X_train, Y_train)

pred_gb = model_gb.predict(X_test)
final_pred_sub_gb = np.expm1(pred_gb)
final_pred_sub_gb

Y_test['ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'] = final_pred_sub_gb
Y_test = Y_test.rename(columns={'ìƒìœ¡ì¼':'DAT', 'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰':'predicted_weight_g'})
Y_test

# for i in range(5):
#   submission = Y_test[i*28:(i*28)+28]
#   submission.to_csv("TEST_0" + str(i+1) + ".csv", mode='w', index=False)

# import zipfile
# path = "/content/drive/MyDrive/01_Prediction/My_Submission/"
# file_list = ['TEST_01.csv', 'TEST_02.csv', 'TEST_03.csv', 'TEST_04.csv', 'TEST_05.csv']
# with zipfile.ZipFile(path + "GradientBoostingRegressor_1.zip", 'w') as my_zip:
#     for i in file_list:
#         my_zip.write(i)
#     my_zip.close()

# Y_test = Y_test.drop(['predicted_weight_g'], axis=1)

"""##### XGBRegressor(ì œì¶œ1) """

model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, 
                             gamma=0.0468, 
                             learning_rate=0.05,
                             min_child_weight=1.7817, 
                             n_estimators=2200,
                             nthread=-1,
                             random_state=7, 
                             reg_alpha=0.464, 
                             reg_lambda=0.8571, 
                             silent=1,
                             subsample=0.5213)

score = rmsle_cv(model_xgb)
xgb_score = score.mean()
print("XGBRegressor score: {:.4f} ({:.4f})".format(score.mean(), score.std()))

model_xgb.fit(X_train, Y_train)

pred_xgb = model_xgb.predict(X_test.values)
final_pred_sub_xgb = np.expm1(pred_xgb)
final_pred_sub_xgb

Y_test['ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'] = final_pred_sub_xgb
Y_test = Y_test.rename(columns={'ìƒìœ¡ì¼':'DAT', 'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰':'predicted_weight_g'})
Y_test

for i in range(5):
  submission = Y_test[i*28:(i*28)+28]
  submission.to_csv("TEST_0" + str(i+1) + ".csv", mode='w', index=False)

import zipfile
path = "/content/drive/MyDrive/01_Prediction/My_Submission/"
file_list = ['TEST_01.csv', 'TEST_02.csv', 'TEST_03.csv', 'TEST_04.csv', 'TEST_05.csv']
with zipfile.ZipFile(path + "XGBRegressor_1218_80(light_delete).zip", 'w') as my_zip:
    for i in file_list:
        my_zip.write(i)
    my_zip.close()

Y_test = Y_test.drop(['predicted_weight_g'], axis=1)

"""##### LGBMRegressor"""

# Kfold Train

model_lgb = lgb.LGBMRegressor(bagging_fraction=0.8, 
                              bagging_freq=5, 
                              bagging_seed=9, 
                              feature_fraction=0.2319, 
                              feature_fraction_seed=9,
                              learning_rate=0.05, 
                              max_bin=55, 
                              min_data_in_leaf=6,
                              min_sum_hessian_in_leaf=11, 
                              n_estimators=720, 
                              num_leaves=5,
                              objective='regression')

score = rmsle_cv(model_lgb)
lgb_score = score.mean()
print("LGBMRegressor score: {:.4f} ({:.4f})".format(score.mean(), score.std()))

model_lgb.fit(X_train, Y_train)

pred_lgb = model_lgb.predict(X_test)
final_pred_sub_lgb = np.expm1(pred_lgb)
final_pred_sub_lgb

Y_test['ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'] = final_pred_sub_lgb
Y_test = Y_test.rename(columns={'ìƒìœ¡ì¼':'DAT', 'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰':'predicted_weight_g'})
Y_test

# for i in range(5):
#   submission = Y_test[i*28:(i*28)+28]
#   submission.to_csv("TEST_0" + str(i+1) + ".csv", mode='w', index=False)

# import zipfile
# path = "/content/drive/MyDrive/01_Prediction/My_Submission/"
# file_list = ['TEST_01.csv', 'TEST_02.csv', 'TEST_03.csv', 'TEST_04.csv', 'TEST_05.csv']
# with zipfile.ZipFile(path + "LGBMRegressor_1.zip", 'w') as my_zip:
#     for i in file_list:
#         my_zip.write(i)
#     my_zip.close()

# Y_test = Y_test.drop(['predicted_weight_g'], axis=1)

"""## â—¾Modeling  
*   [1219_blending_7.zip]  
  **ì œì¶œ2_) public score: 5.0744434425**  
---

1. í‰ê°€ì§€í‘œ  
ëŒ€íšŒì˜ í‰ê°€ì§€í‘œëŠ” RMSEì´ë‚˜, íƒ€ê¹ƒê°’ì— logë¥¼ ì·¨í–ˆê¸° ë•Œë¬¸ì— RMSEë¥¼ êµ¬í•˜ëŠ”ê²Œ RMSLEë¥¼ êµ¬í•˜ëŠ” ê²ƒê³¼ ë™ì¹˜.  
í•™ìŠµì—ëŠ” ì´ë¥¼ ì‚¬ìš©í•˜ê³ , test íŒŒì¼ì—ì„œëŠ” ì—­ë³€í™˜ì„ í•´ì„œ RMSEê°€ ì œëŒ€ë¡œ í‰ê°€ë  ìˆ˜ ìˆê²Œ ì§„í–‰.

2. êµì°¨ê²€ì¦

3. ëª¨ë¸ ë¹„êµ  
ì—¬ëŸ¬ê°œì˜ ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ RMSLEë¥¼ ë¹„êµí•˜ê³ , ê°€ì¥ ë‚®ì€ RMSLEê°€ ë‚˜ì˜¨ ëª¨ë¸ì„ ì„ ì •í•´ íŠœë‹.  
'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'ì„ ì˜ˆì¸¡í•˜ëŠ” íšŒê·€ ëª¨í˜•ì„ ì‚¬ìš©.  

  -  ëª¨ë¸ ëª©ë¡  
  GradientBoosting Regressor  
  XGBoost Regressor  
  LightGBM Regressor
"""

def time_series_df(df, df_target, FEATURES):
  df = df[FEATURES]
  data_list = []
  ts_df = pd.DataFrame()
  for idx in range(len(df_target)): # 644
      time_series = df[24*idx:24*(idx+1)].values  # case1-1, case1-2, case1-3, ...
      time_series = time_series.tolist()
      time_series = sum(time_series, []) # 2 dim -> 1 dim
      time_series_transepose = pd.DataFrame(time_series).transpose()
      ts_df = ts_df.append(time_series_transepose)
      # train_data_list.append(torch.Tensor(time_series))
  return ts_df

FEATURES = ['ìƒìœ¡ì¼', 'ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜', 'ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜', 'co2ê´€ì¸¡ì¹˜', 'ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰', 'ì‹œê°„ë‹¹ì´ê´‘ëŸ‰', 'ì¼ê°„ëˆ„ì ì´ê´‘ëŸ‰', 'ec_ì‹œê°„ë‹¹ë¶„ë¬´ëŸ‰_ì‹œê°„ë‹¹ì´ê´‘ëŸ‰']

ts_train_df = time_series_df(train_df, train_target, FEATURES)
ts_valid_df = time_series_df(valid_df, valid_target, FEATURES)
ts_test_df = time_series_df(test_df, test_target, FEATURES)

ts_train_target = train_target['log_weight']
ts_valid_target = train_target['log_weight']
ts_test_target = test_target

ts_train_valid_df = ts_train_df.append(ts_valid_df).reset_index(drop=True)
ts_train_valid_target_df = train_target.append(valid_target).reset_index(drop=True)
ts_train_valid_target_df = ts_train_valid_target_df['log_weight']

print(ts_train_valid_df.shape, ts_train_valid_target_df.shape) # log_weight
print(ts_test_df.shape, ts_test_target.shape)   # ìƒì¶”	ìƒìœ¡ì¼	ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰

from scipy import sparse

X_train = sparse.csr_matrix(ts_train_valid_df)
Y_train = ts_train_valid_target_df.values 

X_test = ts_test_df
Y_test = test_target

X_train.shape, Y_train.shape

#Validation function
n_folds = 5

def RMSE(y, y_pred):
    rmse = mean_squared_error(y, y_pred) ** 0.5
    return rmse

def rmsle_cv(model):
    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train)
    rmse= np.sqrt(-cross_val_score(model, X_train, Y_train, scoring="neg_mean_squared_error", cv = kf))
    return(rmse)

"""##### GradientBoostingRegressor"""

model_gb = GradientBoostingRegressor(learning_rate=0.05, 
                                     loss='huber', 
                                     max_depth=4,
                                     max_features='sqrt', 
                                     min_samples_leaf=15,
                                     min_samples_split=10, 
                                     n_estimators=3000,
                                     random_state=2020)

score = rmsle_cv(model_gb)
gb_score = score.mean()
print("GradientBoostingRegressor score: {:.4f} ({:.4f})".format(score.mean(), score.std()))

model_gb.fit(X_train, Y_train)

pred_gb = model_gb.predict(X_test)
final_pred_sub_gb = np.expm1(pred_gb)
final_pred_sub_gb

Y_test['ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'] = final_pred_sub_gb
Y_test = Y_test.rename(columns={'ìƒìœ¡ì¼':'DAT', 'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰':'predicted_weight_g'})
Y_test

for i in range(5):
  submission = Y_test[i*28:(i*28)+28]
  submission.to_csv("TEST_0" + str(i+1) + ".csv", mode='w', index=False)

import zipfile
path = "/content/drive/MyDrive/01_Prediction/My_Submission/"
file_list = ['TEST_01.csv', 'TEST_02.csv', 'TEST_03.csv', 'TEST_04.csv', 'TEST_05.csv']
with zipfile.ZipFile(path + "GradientBoostingRegressor.zip", 'w') as my_zip:
    for i in file_list:
        my_zip.write(i)
    my_zip.close()

# Y_test = Y_test.drop(['predicted_weight_g'], axis=1)

"""##### XGBRegressor"""

model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, 
                             gamma=0.0468, 
                             learning_rate=0.05,
                             min_child_weight=1.7817, 
                             n_estimators=2200,
                             nthread=-1,
                             random_state=7, 
                             reg_alpha=0.464, 
                             reg_lambda=0.8571, 
                             silent=1,
                             subsample=0.5213)

score = rmsle_cv(model_xgb)
xgb_score = score.mean()
print("XGBRegressor score: {:.4f} ({:.4f})".format(score.mean(), score.std()))

model_xgb.fit(X_train, Y_train)

pred_xgb = model_xgb.predict(X_test.values)
final_pred_sub_xgb = np.expm1(pred_xgb)
final_pred_sub_xgb

Y_test['ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'] = final_pred_sub_xgb
Y_test = Y_test.rename(columns={'ìƒìœ¡ì¼':'DAT', 'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰':'predicted_weight_g'})
Y_test

for i in range(5):
  submission = Y_test[i*28:(i*28)+28]
  submission.to_csv("TEST_0" + str(i+1) + ".csv", mode='w', index=False)

import zipfile
path = "/content/drive/MyDrive/01_Prediction/My_Submission/"
file_list = ['TEST_01.csv', 'TEST_02.csv', 'TEST_03.csv', 'TEST_04.csv', 'TEST_05.csv']
with zipfile.ZipFile(path + "XGBRegressor.zip", 'w') as my_zip:
    for i in file_list:
        my_zip.write(i)
    my_zip.close()

Y_test = Y_test.drop(['predicted_weight_g'], axis=1)

"""##### LGBMRegressor"""

model_lgb = lgb.LGBMRegressor(objective='regression',
                              num_leaves=5,
                              learning_rate=0.05, 
                              n_estimators=720,
                              max_bin = 55, 
                              bagging_fraction = 0.8,
                              bagging_freq = 5, 
                              feature_fraction = 0.2319,
                              feature_fraction_seed=9, 
                              bagging_seed=9,
                              min_data_in_leaf =6, 
                              min_sum_hessian_in_leaf = 11)

score = rmsle_cv(model_lgb)
lgb_score = score.mean()
print("LGBMRegressor score: {:.4f} ({:.4f})".format(score.mean(), score.std()))

model_lgb.fit(X_train, Y_train)

pred_lgb = model_lgb.predict(X_test)
final_pred_sub_lgb = np.expm1(pred_lgb)
final_pred_sub_lgb

Y_test['ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'] = final_pred_sub_lgb
Y_test = Y_test.rename(columns={'ìƒìœ¡ì¼':'DAT', 'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰':'predicted_weight_g'})
Y_test

for i in range(5):
  submission = Y_test[i*28:(i*28)+28]
  submission.to_csv("TEST_0" + str(i+1) + ".csv", mode='w', index=False)

import zipfile
path = "/content/drive/MyDrive/01_Prediction/My_Submission/"
file_list = ['TEST_01.csv', 'TEST_02.csv', 'TEST_03.csv', 'TEST_04.csv', 'TEST_05.csv']
with zipfile.ZipFile(path + "LGBMRegressor.zip", 'w') as my_zip:
    for i in file_list:
        my_zip.write(i)
    my_zip.close()

Y_test = Y_test.drop(['predicted_weight_g'], axis=1)

"""##### Blending(ì œì¶œ2) """

total_weight = (1./gb_score) + (1./xgb_score) + (1./lgb_score)
pred = (pred_gb * (1./gb_score) + pred_xgb * (1./xgb_score) +  pred_lgb * (1./lgb_score))/total_weight
final_pred_sub_Ensemble = np.expm1(pred)
final_pred_sub_Ensemble

Y_test['ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰'] = final_pred_sub_Ensemble
Y_test = Y_test.rename(columns={'ìƒìœ¡ì¼':'DAT', 'ìƒìœ¡ì¼ë³„_ì_ì¤‘ëŸ‰':'predicted_weight_g'})
Y_test

for i in range(5):
  submission = Y_test[i*28:(i*28)+28]
  submission.to_csv("TEST_0" + str(i+1) + ".csv", mode='w', index=False)

import zipfile
path = "/content/drive/MyDrive/01_Prediction/My_Submission/"
file_list = ['TEST_01.csv', 'TEST_02.csv', 'TEST_03.csv', 'TEST_04.csv', 'TEST_05.csv']
with zipfile.ZipFile(path + "1219_blending_7.zip", 'w') as my_zip:
    for i in file_list:
        my_zip.write(i)
    my_zip.close()

# Y_test = Y_test.drop(['predicted_weight_g'], axis=1)

"""## Model Weight ì €ì¥ """

import pickle

# ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ
xgb_model = model_xgb

# íŒŒì¼ëª…
filename = '/content/drive/MyDrive/01_Prediction/weights/xgb_model.model'

# ëª¨ë¸ ì €ì¥
pickle.dump(xgb_model, open(filename, 'wb'))

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
xgb_model = pickle.load(open(filename, 'rb'))